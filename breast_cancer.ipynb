{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c13cfd25-9392-4cad-8bf3-3a0a72e6c5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.preprocessing import StandardScaler , LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9891079-a14e-4851-9495-c9eea1bce5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/gscdit/Breast-Cancer-Detection/refs/heads/master/data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0907d106-affe-4224-a99e-028aa38b2052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 33)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24202483-63ee-48b1-9c6a-bff2939e2747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id\n",
      "diagnosis\n",
      "radius_mean\n",
      "texture_mean\n",
      "perimeter_mean\n",
      "area_mean\n",
      "smoothness_mean\n",
      "compactness_mean\n",
      "concavity_mean\n",
      "concave points_mean\n",
      "symmetry_mean\n",
      "fractal_dimension_mean\n",
      "radius_se\n",
      "texture_se\n",
      "perimeter_se\n",
      "area_se\n",
      "smoothness_se\n",
      "compactness_se\n",
      "concavity_se\n",
      "concave points_se\n",
      "symmetry_se\n",
      "fractal_dimension_se\n",
      "radius_worst\n",
      "texture_worst\n",
      "perimeter_worst\n",
      "area_worst\n",
      "smoothness_worst\n",
      "compactness_worst\n",
      "concavity_worst\n",
      "concave points_worst\n",
      "symmetry_worst\n",
      "fractal_dimension_worst\n",
      "Unnamed: 32\n"
     ]
    }
   ],
   "source": [
    "for feature in df:\n",
    "    print(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8008990b-0288-40f1-a96d-5e4eef4caf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns = [\"id\",\"Unnamed: 32\"],inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e9708cb-bd0f-4a39-ad14-1acb1e1aada5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(df.iloc[:,1:],df.iloc[:,0],test_size =0.2)\n",
    "\n",
    "\n",
    "\n",
    "# df.iloc[:, 1:]\n",
    "# : â†’ all rows (from top to bottom)\n",
    "# 1: â†’ starting from column index 1 up to the last column\n",
    "# âœ… So this gives you all rows and all columns except the first one\n",
    "# (because the first column is index 0)\n",
    "\n",
    "\n",
    "# df.iloc[:, 0]\n",
    "# : â†’ all rows\n",
    "# 0 â†’ only column at index 0 (the first column)\n",
    "# âœ… So this gives you all rows from the first column only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4daf56-781f-441e-a930-1cc249005257",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "df97e928-a9ea-4b96-b13a-01f158dc149d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.10680502, -0.5570005 ,  0.05533528, ..., -0.5567952 ,\n",
       "        -0.74652755, -0.9892905 ],\n",
       "       [-0.70787383,  1.18989216, -0.65778755, ...,  0.23722664,\n",
       "        -0.15579705,  0.91347106],\n",
       "       [-0.53665319, -0.63295236, -0.54506297, ..., -0.43100956,\n",
       "        -0.46983482, -0.41801087],\n",
       "       ...,\n",
       "       [-0.82662363,  0.12886776, -0.86045194, ..., -1.31211376,\n",
       "        -0.57338241, -0.41575508],\n",
       "       [ 0.07642716,  0.01609077,  0.05693421, ..., -0.28980309,\n",
       "        -0.71936753, -0.50034732],\n",
       "       [-0.46761261, -0.04605166, -0.43593599, ..., -0.33954284,\n",
       "        -1.31349303, -0.65543311]], shape=(455, 30))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a2a909ff-ba5c-4836-b747-277a0dd9534d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "486    B\n",
       "537    B\n",
       "74     B\n",
       "239    M\n",
       "430    M\n",
       "      ..\n",
       "7      M\n",
       "432    M\n",
       "522    B\n",
       "448    B\n",
       "355    B\n",
       "Name: diagnosis, Length: 455, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5277559e-5d0e-45e0-9dc8-8d00e516d330",
   "metadata": {},
   "source": [
    "# since the above col is in char form we need to encode it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad2b4e4-c428-45f9-8f02-ca2e9271be50",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e761377b-a048-43e0-a0d5-e6e86831a12f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6eddab-af4c-4a34-838e-14f42334c89b",
   "metadata": {},
   "source": [
    "**convert numpy array to tensor of tensorFlow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f0e36821-d843-4b25-bc60-9fcb41a1f147",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tensor = torch.from_numpy(X_train)\n",
    "X_test_tensor = torch.from_numpy(X_test)\n",
    "y_train_tensor = torch.from_numpy(y_train)\n",
    "y_test_tensor = torch.from_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba9ec85d-8410-4a05-be44-65490a5cb8ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([455, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "006c8c67-10d6-41fe-8fec-97f6ff07b701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1068, -0.5570,  0.0553,  ..., -0.5568, -0.7465, -0.9893],\n",
       "        [-0.7079,  1.1899, -0.6578,  ...,  0.2372, -0.1558,  0.9135],\n",
       "        [-0.5367, -0.6330, -0.5451,  ..., -0.4310, -0.4698, -0.4180],\n",
       "        ...,\n",
       "        [-0.8266,  0.1289, -0.8605,  ..., -1.3121, -0.5734, -0.4158],\n",
       "        [ 0.0764,  0.0161,  0.0569,  ..., -0.2898, -0.7194, -0.5003],\n",
       "        [-0.4676, -0.0461, -0.4359,  ..., -0.3395, -1.3135, -0.6554]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31796b72-2434-4d0b-8b98-6a309a5c5828",
   "metadata": {},
   "source": [
    "# model Defining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81ffd45f-ff49-4dbd-a87e-926de68cec64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we use OOP concept ... we create the class and then write the functions within it \n",
    "class MySimpleNN():\n",
    "    def __init__(self,X):  #here X is the training dataset\n",
    "        self.weights = torch.rand(X.shape[1], 1, dtype= torch.float64,requires_grad = True)\n",
    "        self.bias = torch.zeros(1, dtype= torch.float64,requires_grad = True)\n",
    "        \n",
    "# explaination:\n",
    "# X.shape => shape of training dataset i.e> [455,30]\n",
    "# X.shape[1]=> i.e> 30 \n",
    "# X.shape[1],1  => this crates a weight matrix of [30 x 1] which helps in calc models weights\n",
    "# dtype= torch.float64  => stors datatype \"float\" \n",
    "# requires_grad=True â†’ ensures parameters are learnable.\n",
    "\n",
    "\n",
    "    \n",
    "    # forward pass\n",
    "    def forward(self,X):\n",
    "        z= torch.matmul(X, self.weights) +self.bias   # this is thr formula to find Z = WiXi + W2X2 + b\n",
    "        y_pred = torch.sigmoid(z)\n",
    "        return y_pred\n",
    "\n",
    "    # loss calculation \n",
    "    def loss(self,y_pred,y):\n",
    "        # clamp predictions to avoid log(0)\n",
    "        epsilon = 1e-7\n",
    "        y_pred = torch.clamp(y_pred, epsilon, 1-epsilon)\n",
    "\n",
    "        # calculate loss\n",
    "        loss = -(y_train_tensor *torch.log(y_pred) + (1- y_train_tensor) * torch.log(1-y_pred)).mean()\n",
    "        return loss\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59732c1-1f9f-41f5-8603-a7b1e41c880d",
   "metadata": {},
   "source": [
    "# Important Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "811a6b01-a836-41b3-9b42-e43e6ee8154e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1 #learning rate \n",
    "epochs = 25"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "726c6320-05df-4057-9d87-818dd5d731b4",
   "metadata": {},
   "source": [
    "# Training Pipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc09c10a-8847-4b8d-b966-75828f198c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :0,loss:3.7436785665178447\n",
      "epoch :1,loss:3.608632610792192\n",
      "epoch :2,loss:3.470460773825422\n",
      "epoch :3,loss:3.330250643708271\n",
      "epoch :4,loss:3.1845730254493803\n",
      "epoch :5,loss:3.0346241054336023\n",
      "epoch :6,loss:2.8787333655771703\n",
      "epoch :7,loss:2.7194001415233497\n",
      "epoch :8,loss:2.558717282735535\n",
      "epoch :9,loss:2.3918854942922394\n",
      "epoch :10,loss:2.2274522591658688\n",
      "epoch :11,loss:2.0670372744996968\n",
      "epoch :12,loss:1.9084496102728696\n",
      "epoch :13,loss:1.7566699975467512\n",
      "epoch :14,loss:1.6102291256895616\n",
      "epoch :15,loss:1.4712192750546091\n",
      "epoch :16,loss:1.339242802810236\n",
      "epoch :17,loss:1.2213622005386626\n",
      "epoch :18,loss:1.119200947263263\n",
      "epoch :19,loss:1.0356204577035708\n",
      "epoch :20,loss:0.9698942288006889\n",
      "epoch :21,loss:0.9198812881361065\n",
      "epoch :22,loss:0.882502506069966\n",
      "epoch :23,loss:0.854533193548142\n",
      "epoch :24,loss:0.8332208869583417\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = MySimpleNN(X_train_tensor)\n",
    "\n",
    "# define loops \n",
    "for epoch in range(epochs):\n",
    "    \n",
    "    # forward pass\n",
    "    y_pred = model.forward(X_train_tensor)\n",
    "    # print(y_pred.shape)\n",
    "    \n",
    "\n",
    "    # loss calculation\n",
    "    loss = model.loss(y_pred,y_train_tensor)\n",
    "    # print(f'epoch :{epoch},loss:{loss.item()}')\n",
    "\n",
    "\n",
    "    # backward pass\n",
    "    loss.backward()\n",
    "\n",
    "    # parameters update\n",
    "    with torch.no_grad():\n",
    "        model.weights -= lr * model.weights.grad\n",
    "        model.bias -= lr * model.bias.grad\n",
    "\n",
    "    # zero gradients\n",
    "    model.weights.grad.zero_()\n",
    "    model.bias.grad.zero_()\n",
    "\n",
    "    # print loss in each epoch \n",
    "    print(f'epoch :{epoch},loss:{loss.item()}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f73e62-53e0-4881-a229-e45649b34c00",
   "metadata": {},
   "source": [
    "# Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4f84c8dc-cd3b-4333-80cf-99cf5f77609c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.652046799659729\n"
     ]
    }
   ],
   "source": [
    "# model evaluation\n",
    "with torch.no_grad():\n",
    "  y_pred = model.forward(X_test_tensor)\n",
    "  y_pred = (y_pred > 0.9).float()\n",
    "  accuracy = (y_pred == y_test_tensor).float().mean()\n",
    "  print(f'Accuracy: {accuracy.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fddd305-97a0-4282-b2b2-b5f133df24f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
